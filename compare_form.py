import pandas as pd
import matplotlib.pyplot as plt

# ==========================================
# 1. Data Setup (Full 100 Epochs Data)
# ==========================================

# We keep the full data here, but we will SLICE it later for plotting
full_epochs = list(range(1, 101))

# Dummy example data (replace with your actual numbers)
# Each list should have the same length as epochs
standard_transformer = {
    "train_loss": [
        8.2162,7.3298,7.1527,6.9992,6.8713,6.7736,6.6927,6.6257,6.5626,6.5032,
        6.4449,6.3907,6.3385,6.29,6.2445,6.2032,6.1639,6.1317,6.0993,6.0645,
        6.0323,6.0008,5.9711,5.9453,5.9181,5.8929,5.8759,5.8521,5.8275,5.8016,
        5.7814,5.7595,5.7387,5.7155,5.6947,5.6735,5.6533,5.6331,5.6149,5.5976,
        5.5796,5.5631,5.5462,5.5323,5.5199,5.5088,5.4951,5.4826,5.4668,5.4525,
        5.44,5.4287,5.4169,5.4073,5.399,5.3894,5.3794,5.3701,5.3615,5.3538,
        5.3448,5.3353,5.3273,5.3204,5.3128,5.3065,5.2999,5.294,5.2895,5.284,
        5.2789,5.2731,5.2685,5.2645,5.26,5.2559,5.2521,5.2491,5.2464,5.2437,
        5.2404,5.2385,5.2371,5.2351,5.2338,5.2318,5.2305,5.2294,5.2279,5.2268,
        5.226,5.2248,5.2238,5.2233,5.2229,5.2235,5.2231,5.2228,5.2226,5.2221
    ],
    "train_ppl": [
        3700.59,1525.04,1277.51,1095.78,964.17,874.49,806.53,754.26,708.14,667.28,
        629.47,596.25,565.97,539.13,515.19,494.34,475.29,460.21,445.57,430.3,
        416.68,403.77,391.92,381.96,371.69,362.47,356.35,347.95,339.5,330.84,
        324.21,317.19,310.67,303.54,297.28,291.05,285.23,279.54,274.48,269.78,
        264.96,260.63,256.25,252.72,249.61,246.86,243.49,240.47,236.69,233.33,
        230.45,227.85,225.18,223.03,221.18,219.07,216.9,214.89,213.04,211.42,
        209.51,207.54,205.89,204.46,202.92,201.65,200.31,199.14,198.24,197.15,
        196.16,195.01,194.12,193.35,192.48,191.69,190.96,190.39,189.89,189.37,
        188.75,188.39,188.12,187.75,187.51,187.13,186.88,186.68,186.39,186.19,
        186.05,185.82,185.64,185.55,185.47,185.58,185.51,185.45,185.42,185.33
    ],
    "valid_loss": [
        7.1521,6.9636,6.8253,6.7013,6.6011,6.541,6.5008,6.4557,6.4133,6.3802,
        6.3284,6.2867,6.2527,6.2232,6.19,6.1618,6.1387,6.1186,6.1004,6.0785,
        6.0773,6.0589,6.0372,6.0233,6.0069,6.0011,5.9996,5.9848,5.9575,5.9425,
        5.9363,5.9158,5.9124,5.9045,5.8953,5.8799,5.8748,5.8687,5.8635,5.8545,
        5.8539,5.8473,5.8427,5.8363,5.827,5.8207,5.824,5.8169,5.8107,5.801,
        5.7963,5.7937,5.7925,5.7972,5.7935,5.7889,5.7868,5.7821,5.7757,5.7711,
        5.7713,5.767,5.7601,5.7593,5.7594,5.7594,5.7556,5.7517,5.751,5.7508,
        5.7465,5.7442,5.7413,5.7384,5.7369,5.7363,5.7355,5.7349,5.7336,5.733,
        5.7323,5.732,5.7318,5.7307,5.7292,5.7292,5.7282,5.728,5.7277,5.7273,
        5.7271,5.7268,5.7267,5.7266,5.7264,5.7264,5.7263,5.7263,5.7263,5.7263
    ],
    "valid_ppl": [
        1276.76,1057.45,920.85,813.43,735.89,693.01,665.67,636.33,609.89,590.02,
        560.26,537.36,519.4,504.32,487.84,474.28,463.46,454.24,446.04,436.39,
        435.87,427.91,418.71,412.96,406.24,403.89,403.28,397.36,386.64,380.89,
        378.54,370.85,369.61,366.67,363.32,357.77,355.97,353.77,351.96,348.79,
        348.6,346.29,344.7,342.51,339.34,337.22,338.31,335.94,333.85,330.64,
        329.08,328.23,327.82,329.36,328.16,326.66,325.98,324.44,322.38,320.89,
        320.95,319.59,317.39,317.14,317.15,317.16,315.96,314.72,314.49,314.44,
        313.1,312.38,311.46,310.57,310.12,309.93,309.68,309.47,309.08,308.91,
        308.69,308.6,308.54,308.19,307.72,307.74,307.42,307.37,307.25,307.13,
        307.09,307,306.95,306.92,306.87,306.86,306.83,306.83,306.83,306.83
    ],
}

hierarchical_transformer_weighted_sum = {
    "train_loss": [
        23.6638,8.3151,7.4824,7.2377,7.0663,6.9228,6.8044,6.7048,6.6215,6.5595,
        6.5021,6.4449,6.394,6.3507,6.3132,6.2788,6.2415,6.2034,6.1684,6.1401,
        6.1098,6.0808,6.0521,6.023,5.992,5.9638,5.9392,5.9148,5.8888,5.8626,
        5.8452,5.8278,5.8117,5.79,5.7706,5.7583,5.739,5.7246,5.7113,5.6948,
        5.6787,5.6656,5.6486,5.6325,5.6193,5.6057,5.5912,5.5777,5.5629,5.551,
        5.5398,5.5302,5.5186,5.5089,5.5001,5.4911,5.4814,5.4721,5.4624,5.4551,
        5.4459,5.4384,5.4285,5.4212,5.4145,5.4059,5.3992,5.3944,5.3877,5.3817,
        5.3763,5.3717,5.3645,5.3581,5.3525,5.3474,5.3429,5.3382,5.3338,5.3292,
        5.3262,5.3224,5.3193,5.3167,5.3147,5.3112,5.3096,5.3073,5.3058,5.3048,
        5.3032,5.302,5.3,5.2995,5.2984,5.2971,5.2971,5.2966,5.2963,5.2964
    ],
    "train_ppl": [
        485165195.4,4084.96,1776.49,1390.83,1171.83,1015.18,901.8,816.31,751.03,705.9,
        666.52,629.49,598.24,572.87,551.78,533.12,513.6,494.41,477.43,464.11,
        450.26,437.36,424.99,412.83,400.22,389.09,379.63,370.47,360.97,351.63,
        345.58,339.63,334.19,327,320.73,316.81,310.74,306.31,302.27,297.33,
        292.56,288.76,283.89,279.36,275.71,271.98,268.07,264.48,260.57,257.49,
        254.63,252.19,249.28,246.88,244.73,242.52,240.17,237.96,235.66,233.95,
        231.82,230.06,227.8,226.15,224.63,222.71,221.23,220.16,218.69,217.4,
        216.21,215.23,213.69,212.32,211.13,210.07,209.12,208.14,207.22,206.28,
        205.65,204.87,204.24,203.72,203.3,202.58,202.27,201.81,201.5,201.3,
        200.99,200.74,200.35,200.23,200.02,199.76,199.75,199.65,199.6,199.61
    ],
    "valid_loss": [
        8.6563,7.2699,7.0405,6.8825,6.75,6.6357,6.5411,6.4687,6.4265,6.374,
        6.3244,6.2944,6.2739,6.2406,6.2198,6.2036,6.1785,6.1487,6.1286,6.1207,
        6.1024,6.0928,6.0649,6.051,6.0341,6.0366,6.0284,6.0149,5.9906,5.9822,
        5.9837,5.9763,5.9741,5.9568,5.9534,5.939,5.9431,5.9461,5.9287,5.9343,
        5.9293,5.913,5.9101,5.9087,5.896,5.9112,5.9012,5.8906,5.8884,5.8892,
        5.8811,5.8826,5.8803,5.8751,5.8677,5.8667,5.8649,5.8581,5.8611,5.8547,
        5.852,5.8615,5.8513,5.8583,5.8548,5.8496,5.8534,5.8494,5.8452,5.8502,
        5.8488,5.8408,5.8391,5.8369,5.8346,5.8293,5.8301,5.8307,5.8296,5.8286,
        5.828,5.8255,5.8259,5.825,5.8243,5.8229,5.8248,5.824,5.8229,5.8224,
        5.8215,5.8212,5.8206,5.8204,5.8204,5.8198,5.8195,5.8191,5.8191,5.8191
    ],
    "valid_ppl": [
        5745.99,1436.35,1141.91,975.05,854.06,761.82,693.05,644.61,618.01,586.39,
        558.02,541.55,530.55,513.16,502.62,494.52,482.25,468.13,458.81,455.2,
        446.94,442.65,430.49,424.53,417.41,418.46,415.04,409.47,399.67,396.3,
        396.91,393.96,393.1,386.36,385.08,379.54,381.11,382.25,375.68,377.76,
        375.89,369.83,368.75,368.21,363.57,369.16,365.48,361.61,360.82,361.13,
        358.2,358.74,357.93,356.07,353.45,353.07,352.44,350.04,351.1,348.89,
        347.92,351.24,347.69,350.12,348.9,347.09,348.43,347.02,345.59,347.29,
        346.83,344.06,343.47,342.7,341.94,340.12,340.39,340.59,340.23,339.88,
        339.69,338.82,338.95,338.67,338.43,337.96,338.6,338.33,337.94,337.79,
        337.49,337.37,337.16,337.1,337.12,336.9,336.8,336.68,336.67,336.66
    ],
}

hierarchical_transformer_C2P_P2C = {
    "train_loss": [
        8.1625,7.2883,7.0993,6.9359,6.8002,6.6942,6.615,6.5464,6.4869,6.4343,
        6.3838,6.3342,6.2819,6.2385,6.1918,6.1535,6.1189,6.0784,6.0413,6.0107,
        5.9889,5.965,5.9334,5.9136,5.8846,5.8581,5.8331,5.813,5.7907,5.7724,
        5.7605,5.7383,5.7178,5.6972,5.6824,5.6624,5.6429,5.6272,5.6137,5.5985,
        5.5842,5.5687,5.5556,5.5459,5.533,5.5188,5.507,5.4949,5.4845,5.4743,
        5.4678,5.4582,5.446,5.4387,5.4306,5.4236,5.413,5.4038,5.394,5.3854,
        5.3769,5.3664,5.358,5.3516,5.3454,5.3407,5.3354,5.3302,5.3254,5.3218,
        5.3187,5.315,5.3095,5.3053,5.3011,5.2971,5.2926,5.2894,5.2862,5.2835,
        5.2808,5.279,5.2766,5.2747,5.2739,5.2718,5.2709,5.2703,5.2694,5.2679,
        5.2673,5.2665,5.2656,5.2654,5.2645,5.2648,5.2647,5.2641,5.2644,5.264
    ],
    "train_ppl": [
        3506.97,1463.04,1211.14,1028.51,898.06,807.69,746.22,696.73,656.48,622.87,
        592.17,563.53,534.79,512.09,488.73,470.35,454.37,436.34,420.45,407.76,
        398.99,389.54,377.44,370.03,359.47,350.07,341.43,334.64,327.23,321.29,
        317.51,310.53,304.24,298.02,293.65,287.84,282.29,277.89,274.15,270.02,
        266.19,262.09,258.69,256.19,252.89,249.34,246.42,243.44,240.94,238.49,
        236.95,234.66,231.83,230.14,228.3,226.69,224.31,222.25,220.08,218.2,
        216.34,214.1,212.29,210.95,209.65,208.67,207.55,206.48,205.49,204.76,
        204.12,203.37,202.26,201.4,200.56,199.76,198.85,198.23,197.59,197.06,
        196.53,196.17,195.71,195.34,195.17,194.77,194.6,194.47,194.29,194.01,
        193.88,193.74,193.56,193.53,193.35,193.41,193.39,193.26,193.34,193.25
    ],
    "valid_loss": [
        7.1306,6.9259,6.7671,6.6453,6.5477,6.4778,6.4125,6.3755,6.335,6.2957,
        6.2594,6.2274,6.1909,6.1618,6.1358,6.1252,6.0996,6.0759,6.0557,6.058,
        6.0501,6.0372,6.0096,5.9812,5.9687,5.9583,5.9527,5.9463,5.9377,5.9209,
        5.9163,5.9137,5.9067,5.8818,5.8821,5.8667,5.8632,5.8618,5.8535,5.8477,
        5.8441,5.8352,5.8211,5.8241,5.8214,5.8129,5.8202,5.8174,5.8094,5.7981,
        5.808,5.7937,5.7924,5.7832,5.7836,5.7826,5.7743,5.7743,5.7686,5.7684,
        5.7657,5.7642,5.7624,5.7604,5.7581,5.7578,5.7579,5.759,5.7614,5.7628,
        5.7607,5.7553,5.7555,5.7523,5.7501,5.7483,5.7462,5.7444,5.7444,5.7436,
        5.7424,5.7425,5.7425,5.7427,5.7417,5.7413,5.741,5.7399,5.7399,5.7396,
        5.7393,5.7389,5.738,5.7379,5.7378,5.7377,5.7375,5.7376,5.7375,5.7375
    ],
    "valid_ppl": [
        1249.63,1018.36,868.81,769.16,697.61,650.55,609.42,587.28,563.97,542.26,
        522.9,506.46,488.27,474.3,462.13,457.26,445.68,435.24,426.56,427.54,
        424.16,418.72,407.3,395.92,391,386.93,384.8,382.34,379.06,372.74,
        371.04,370.07,367.47,358.44,358.58,353.07,351.84,351.37,348.46,346.43,
        345.2,342.14,337.34,338.37,337.45,334.58,337.03,336.09,333.42,329.68,
        332.97,328.24,327.79,324.8,324.93,324.59,321.93,321.93,320.09,320.01,
        319.15,318.68,318.1,317.46,316.74,316.65,316.69,317.04,317.8,318.23,
        317.57,315.87,315.92,314.92,314.21,313.66,312.99,312.43,312.43,312.19,
        311.81,311.84,311.85,311.92,311.58,311.46,311.37,311.04,311.04,310.95,
        310.86,310.73,310.45,310.41,310.37,310.36,310.3,310.31,310.3,310.3
    ],
}

# ==========================================
# 2. Plotting Function
# ==========================================

# ==========================================
# 2. Filtering Function (Extract epochs 10-90)
# ==========================================

# Indices 9 to 90 correspond to Epochs 10 to 90
START_IDX = 9 
END_IDX = 90  

# Create the specific epoch range for the X-axis
epochs_slice = full_epochs[START_IDX:END_IDX]

def get_sliced_data(data_dict, key):
    return data_dict[key][START_IDX:END_IDX]

# ==========================================
# 3. Plotting Function
# ==========================================

def plot_metric(metric_name, std_data, hier_data, weighted_data):
    plt.figure(figsize=(10, 6))
    
    # Plotting lines using the SLICED data and SLICED epochs
    plt.plot(epochs_slice, std_data, label="Standard Transformer", color='blue', linestyle='-', linewidth=1.5)
    plt.plot(epochs_slice, hier_data, label="Hierarchical Transformer (C2P-P2C)", color='green', linestyle='--', linewidth=1.5)
    plt.plot(epochs_slice, weighted_data, label="Hierarchical Transformer (Weighted Sum)", color='orange', linestyle='-.', linewidth=1.5)
    
    plt.xlabel("Epoch")
    plt.ylabel(metric_name)
    plt.title(f"{metric_name} vs Epoch (Epochs 10-90)")
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.7)
    
    # Since we are filtering the massive spike, we might NOT need log scale anymore,
    # but let's keep it optional or just linear if the values are close.
    # For 10-90 range, values are much closer, so linear scale often works better to see small differences.
    # However, if you still want log scale for PPL, uncomment the next two lines:
    # if "PPL" in metric_name:
    #     plt.yscale('log')
        
    plt.tight_layout()
    plt.show()

# ==========================================
# 4. Generate the Four Plots (Sliced 10-90)
# ==========================================

# 1. Train Loss
plot_metric("Train Loss",
            get_sliced_data(standard_transformer, "train_loss"),
            get_sliced_data(hierarchical_transformer_C2P_P2C, "train_loss"),
            get_sliced_data(hierarchical_transformer_weighted_sum, "train_loss"))

# 2. Train PPL 
plot_metric("Train PPL",
            get_sliced_data(standard_transformer, "train_ppl"),
            get_sliced_data(hierarchical_transformer_C2P_P2C, "train_ppl"),
            get_sliced_data(hierarchical_transformer_weighted_sum, "train_ppl"))

# 3. Valid Loss
plot_metric("Valid Loss",
            get_sliced_data(standard_transformer, "valid_loss"),
            get_sliced_data(hierarchical_transformer_C2P_P2C, "valid_loss"),
            get_sliced_data(hierarchical_transformer_weighted_sum, "valid_loss"))

# 4. Valid PPL 
plot_metric("Valid PPL",
            get_sliced_data(standard_transformer, "valid_ppl"),
            get_sliced_data(hierarchical_transformer_C2P_P2C, "valid_ppl"),
            get_sliced_data(hierarchical_transformer_weighted_sum, "valid_ppl"))
